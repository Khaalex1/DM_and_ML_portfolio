{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lab 3 : Feature selection","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\n\n# Scikit-Learn â‰¥0.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\nfrom sklearn.preprocessing import StandardScaler #the Standard Scaler : X2 = (X1 - E(X1))/sqrt(Var(X1))\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.naive_bayes import GaussianNB\n\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib as mlp\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\n\n#!pip install pymrmr\n!pip install mrmr_selection","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:53:19.405432Z","iopub.execute_input":"2022-09-29T10:53:19.406567Z","iopub.status.idle":"2022-09-29T10:53:35.403956Z","shell.execute_reply.started":"2022-09-29T10:53:19.406430Z","shell.execute_reply":"2022-09-29T10:53:35.402112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading \n\nThis step loads the images contained in the training dataset.","metadata":{"execution":{"iopub.status.busy":"2022-09-27T03:50:05.298454Z","iopub.execute_input":"2022-09-27T03:50:05.298855Z","iopub.status.idle":"2022-09-27T03:50:05.306499Z","shell.execute_reply.started":"2022-09-27T03:50:05.298819Z","shell.execute_reply":"2022-09-27T03:50:05.305011Z"}}},{"cell_type":"code","source":"def process_image(img, size, grey_scale=True):\n    '''\n    This function reduces the size of the image and converts \n    it to a grey_scale image.\n    '''\n    img = cv2.resize(img, size)\n    if grey_scale:\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)/size[0]\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:53:35.408149Z","iopub.execute_input":"2022-09-29T10:53:35.408750Z","iopub.status.idle":"2022-09-29T10:53:35.416347Z","shell.execute_reply.started":"2022-09-29T10:53:35.408706Z","shell.execute_reply":"2022-09-29T10:53:35.415426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train Dataset","metadata":{}},{"cell_type":"code","source":"labels = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\ntrain_img = [] #contains the images used for training the model\ntrain_labels = [] #label of each image in x_train \nPATH = '../input/brain-tumor-classification-mri/Training'\nnew_size = (255, 255)\n\nfor label in labels:\n    img_dir = os.path.join(PATH, label)\n    for img_file in os.listdir(img_dir):\n        img = cv2.imread(f'{img_dir}/{img_file}')\n        img = process_image(img, new_size)\n        train_img.append(img)\n        train_labels.append(label)\n        \ntrain_img = np.stack(train_img)\ntrain_labels = np.stack(train_labels)\n\nprint(\"train_img shape : \", train_img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:53:35.418176Z","iopub.execute_input":"2022-09-29T10:53:35.418644Z","iopub.status.idle":"2022-09-29T10:54:00.051821Z","shell.execute_reply.started":"2022-09-29T10:53:35.418601Z","shell.execute_reply":"2022-09-29T10:54:00.050552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Dataset","metadata":{}},{"cell_type":"code","source":"labels = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\ntest_img = [] #contains the images used for testing the model\ntest_labels = [] #label of each image in test_img\nPATH = '../input/brain-tumor-classification-mri/Testing'\nnew_size = (255, 255)\n\nfor label in labels:\n    img_dir = os.path.join(PATH, label)\n    for img_file in os.listdir(img_dir):\n        img = cv2.imread(f'{img_dir}/{img_file}')\n        img = process_image(img, new_size)\n        test_img.append(img)\n        test_labels.append(label)\n        \ntest_img = np.stack(test_img)\ntest_labels = np.stack(test_labels)\n\nprint(\"test_img shape : \", test_img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:00.053342Z","iopub.execute_input":"2022-09-29T10:54:00.054151Z","iopub.status.idle":"2022-09-29T10:54:03.251729Z","shell.execute_reply.started":"2022-09-29T10:54:00.054112Z","shell.execute_reply":"2022-09-29T10:54:03.250267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert Brain Tumor classes to numerical values","metadata":{}},{"cell_type":"code","source":"class_map = {\n    'no_tumor': 0,\n    'glioma_tumor': 1,\n    'pituitary_tumor': 2,\n    'meningioma_tumor': 3\n}\n\ntrain_labels = np.array([class_map[label] for label in train_labels])\ntest_labels = np.array([class_map[label] for label in test_labels])","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:03.255647Z","iopub.execute_input":"2022-09-29T10:54:03.256299Z","iopub.status.idle":"2022-09-29T10:54:03.263749Z","shell.execute_reply.started":"2022-09-29T10:54:03.256260Z","shell.execute_reply":"2022-09-29T10:54:03.262716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reduced dataset creation : 300 samples per class","metadata":{}},{"cell_type":"code","source":"list_index = []\n\nglioma_index = np.where(train_labels == 1)[0][0]\nlist_index.append(glioma_index)\n\nmeningioma_index = np.where(train_labels == 2)[0][0]\nlist_index.append(meningioma_index)\n\nno_tumor_index = np.where(train_labels == 0)[0][0]\nlist_index.append(no_tumor_index)\n\npituitary_index = np.where(train_labels == 3)[0][0]\nlist_index.append(pituitary_index)\n\nx = []\ny = []\nfor ind in list_index:\n    x.append(train_img[ind : ind+300])\n    y.append(train_labels[ind : ind + 300])\n\n\nflat_x = np.stack(x)\nflat_x = flat_x.reshape((flat_x.shape[0]*flat_x.shape[1], 255*255))\n\nflat_y = np.stack(y)\nflat_y = flat_y.reshape((flat_y.shape[0]*flat_y.shape[1]))\n\nprint(\"dataset shape : \", flat_x.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:03.265261Z","iopub.execute_input":"2022-09-29T10:54:03.265837Z","iopub.status.idle":"2022-09-29T10:54:03.595898Z","shell.execute_reply.started":"2022-09-29T10:54:03.265797Z","shell.execute_reply":"2022-09-29T10:54:03.594670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Ranking\n\nWe would use a dictionary to store the rankings of features from each feature selection algortihm","metadata":{}},{"cell_type":"code","source":"rankings = dict()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:03.597565Z","iopub.execute_input":"2022-09-29T10:54:03.597990Z","iopub.status.idle":"2022-09-29T10:54:03.603365Z","shell.execute_reply.started":"2022-09-29T10:54:03.597949Z","shell.execute_reply":"2022-09-29T10:54:03.602164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Selection\n\n","metadata":{}},{"cell_type":"markdown","source":"### Dimensionality reduction by PCA implementation\n\nPCA enables to extract a specific number of features while conserving an acceptable amount of information (variance) from original features . \nIt consists in projecting the original dataset (standardized) in a less dimensional space such that its variance is maximized, given by the formula : $X_{pca} = X_{original}.W$, the number of W columns corresponding to the number of extracted features.\nThe first component is : \n\n$$w_{1} = \\underset{||w||=1}{argmax}\\Bigg\\{||Xw||^{2}\\Bigg\\} = \\underset{w}{argmax}\\Bigg\\{\\frac{w^{T}X^{T}Xw}{w^{T}w}\\Bigg\\} $$\n\n\nOther W components are obtained by first computing the substraction of $k-1$ PC:\n$$\\hat{X}_{k} = X -  \\sum \\limits_{j=1}^{k-1} Xw_{j}w_{j}^{T}$$\n\nAnd then by computing : \n\n$$w_{k} = \\underset{w}{argmax}\\Bigg\\{\\frac{w^{T}\\hat{X}_{k}^{T}\\hat{X}_{k}w}{w^{T}w}\\Bigg\\}$$\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nflat_train, flat_test, y_train, y_test = train_test_split(flat_x, flat_y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:03.605041Z","iopub.execute_input":"2022-09-29T10:54:03.605712Z","iopub.status.idle":"2022-09-29T10:54:03.896098Z","shell.execute_reply.started":"2022-09-29T10:54:03.605667Z","shell.execute_reply":"2022-09-29T10:54:03.894821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"S = StandardScaler()\nflat_train = S.fit_transform(flat_train) \n\npca = PCA().fit(flat_train)\n\nplt.figure()\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.grid()\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance')\nplt.title('cumvar(PCA components)')\n","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:03.897657Z","iopub.execute_input":"2022-09-29T10:54:03.897966Z","iopub.status.idle":"2022-09-29T10:54:23.668286Z","shell.execute_reply.started":"2022-09-29T10:54:03.897939Z","shell.execute_reply":"2022-09-29T10:54:23.667070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Conserving ~300 features from the images already allows to keep 90% of the original dataset variance. We choose then to perform a PCA with 300 components. So the final samples have 300 features","metadata":{}},{"cell_type":"code","source":"# also possible to specify variance explained ration instead of number of components \n# e.g. nb_components = 0.9 means conserving 90% of original variance\n\npca = PCA(n_components = 300)\n\npca_train = pca.fit_transform(flat_train)\nrankings['pca'] = pca_train\nprint(\"dataset final shape : \", pca_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:23.669997Z","iopub.execute_input":"2022-09-29T10:54:23.670609Z","iopub.status.idle":"2022-09-29T10:54:35.653642Z","shell.execute_reply.started":"2022-09-29T10:54:23.670571Z","shell.execute_reply":"2022-09-29T10:54:35.652400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inverse PCA (300 features) transform and 3D Visualization","metadata":{}},{"cell_type":"code","source":"# comparing original samples and their PCA inverser transform\ndef compare(label = 'no_tumor'):\n    #all index of a certain class \n    clas = class_map[label]\n    ind = np.where(y_train == clas)[0]\n    rand_ind = np.random.choice(ind)\n\n    #PCA inverse transform\n    X_inv = pca.inverse_transform(pca_train)\n\n    #original sample\n    x_orig = flat_train[rand_ind].reshape(255,255)\n    #pca inv transform sample\n    x_pca = X_inv[rand_ind].reshape(255,255)\n\n    #plot comparison between original and pca inverse transform\n    fig, axs = plt.subplots(1,2, figsize = (15, 5))\n    im1 = axs[0].imshow(x_orig, cmap = 'gray')\n    axs[0].set_title('Original train sample, class = {}'.format(label))\n    plt.colorbar(im1, ax = axs[0])\n\n    im2 = axs[1].imshow(x_pca, cmap = 'gray')\n    axs[1].set_title('Inverse PCA transform of same train sample, class = {}'.format(label))\n    plt.colorbar(im2, ax = axs[1])\n    fig.tight_layout()\n    plt.show()\n    \nfor key in class_map.keys():\n    compare(label = key)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:35.655033Z","iopub.execute_input":"2022-09-29T10:54:35.655393Z","iopub.status.idle":"2022-09-29T10:54:41.449348Z","shell.execute_reply.started":"2022-09-29T10:54:35.655359Z","shell.execute_reply":"2022-09-29T10:54:41.448156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter_x = pca_train[:, 0]\nscatter_y = pca_train[:, 1]\nscatter_z = pca_train[:, 2]\ngroup = y_train\n\ncdict = {0: 'red', 1: 'blue', 2: 'green', 3 : \"orange\"}\nidentification = {v : k for k,v in class_map.items()}\n\n\nplt.figure()\nax = plt.axes(projection = '3d')\nplt.grid()\nfor g in np.unique(group):\n    ix = np.where(group == g)\n    ax.scatter3D(scatter_x[ix], scatter_y[ix], scatter_z[ix], c = cdict[g], label = identification[g], s = 30)\nax.legend(bbox_to_anchor =(1.95,0.75))\nplt.xlabel(\"PCA feature 1\")\nplt.ylabel(\"PCA feature 2\")\nax.set_zlabel(\"PCA feature 3\")\nplt.title(\"Classes 3D features (by PCA) representation\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:41.451187Z","iopub.execute_input":"2022-09-29T10:54:41.451663Z","iopub.status.idle":"2022-09-29T10:54:42.038779Z","shell.execute_reply.started":"2022-09-29T10:54:41.451619Z","shell.execute_reply":"2022-09-29T10:54:42.037434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"The 3D representation in PCA space seems to show poor separability of the samples. We will then test different classical algorithms to check this out. ","metadata":{}},{"cell_type":"markdown","source":"## F - Statistic","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import f_classif\n\nprint(flat_x.shape)\nprint(flat_y.shape)\n\nf_selected_features = f_classif(flat_train, y_train)[0]\nrankings['f'] = f_selected_features","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:42.040838Z","iopub.execute_input":"2022-09-29T10:54:42.041615Z","iopub.status.idle":"2022-09-29T10:54:42.741982Z","shell.execute_reply.started":"2022-09-29T10:54:42.041554Z","shell.execute_reply":"2022-09-29T10:54:42.740765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"/!\\ Plot testing /!\\","metadata":{}},{"cell_type":"code","source":"plt.imshow(f_selected_features.reshape(255,255), cmap='Blues_r')\nplt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:42.747597Z","iopub.execute_input":"2022-09-29T10:54:42.747972Z","iopub.status.idle":"2022-09-29T10:54:43.057090Z","shell.execute_reply.started":"2022-09-29T10:54:42.747939Z","shell.execute_reply":"2022-09-29T10:54:43.055872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Maximum Relevance Minimum Redundancy (MRMR)\n\nThe goal of this method is to substract features that have high relevancy to the labels as well as little redundacy with one another \n[1](http://)","metadata":{}},{"cell_type":"markdown","source":"### Reduce image size for MRMR","metadata":{}},{"cell_type":"code","source":"new_size = (100,100)\ntrain_img_mrmr = [process_image(img, new_size, grey_scale=False) for img in train_img]\n\nx = []\ny = []\nfor ind in list_index:\n    x.append(train_img_mrmr[ind : ind+300])\n    y.append(train_labels[ind : ind + 300])\n\n\nflat_x = np.stack(x)\nflat_x = flat_x.reshape((flat_x.shape[0]*flat_x.shape[1], 100*100))\n\nflat_y = np.stack(y)\nflat_y = flat_y.reshape((flat_y.shape[0]*flat_y.shape[1]))\n\nprint(\"dataset shape : \", flat_x.shape)\n\nflat_train, flat_test, y_train, y_test = train_test_split(flat_x, flat_y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:43.058743Z","iopub.execute_input":"2022-09-29T10:54:43.059185Z","iopub.status.idle":"2022-09-29T10:54:43.322250Z","shell.execute_reply.started":"2022-09-29T10:54:43.059142Z","shell.execute_reply":"2022-09-29T10:54:43.320969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import mrmr\n\nX = pd.DataFrame(flat_train)\ny = pd.Series(y_train)\n\n# select top 10 features using mRMR\nfrom mrmr import mrmr_classif\nmrmr_selected_features = mrmr_classif(X=X, y=y, K=100)\n\nrankings['mrmr'] = mrmr_selected_features","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:54:43.323963Z","iopub.execute_input":"2022-09-29T10:54:43.324577Z","iopub.status.idle":"2022-09-29T10:59:15.701203Z","shell.execute_reply.started":"2022-09-29T10:54:43.324528Z","shell.execute_reply":"2022-09-29T10:59:15.699705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mrmr_selected_features = np.array(mrmr_selected_features)\n\nplt.imshow(mrmr_selected_features.reshape(10,10), cmap='Blues_r')\nplt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T11:09:02.204676Z","iopub.execute_input":"2022-09-29T11:09:02.205706Z","iopub.status.idle":"2022-09-29T11:09:02.471233Z","shell.execute_reply.started":"2022-09-29T11:09:02.205666Z","shell.execute_reply":"2022-09-29T11:09:02.469989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Mutual Information","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif\nmi_selected_features = mutual_info_classif(flat_train, y_train)\n\nrankings['mi'] = mi_selected_features","metadata":{"execution":{"iopub.status.busy":"2022-09-29T11:10:53.618060Z","iopub.execute_input":"2022-09-29T11:10:53.618745Z","iopub.status.idle":"2022-09-29T11:11:56.583057Z","shell.execute_reply.started":"2022-09-29T11:10:53.618708Z","shell.execute_reply":"2022-09-29T11:11:56.581551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(mi_selected_features.reshape(128,128), cmap='Blues_r')\nplt.colorbar()","metadata":{"execution":{"iopub.status.busy":"2022-09-29T11:10:50.642774Z","iopub.execute_input":"2022-09-29T11:10:50.643546Z","iopub.status.idle":"2022-09-29T11:10:50.665012Z","shell.execute_reply.started":"2022-09-29T11:10:50.643505Z","shell.execute_reply":"2022-09-29T11:10:50.663614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split Dataset and Test with some classical classifiers","metadata":{}},{"cell_type":"code","source":"algos = ['mrmr', 'mi']  # feature selection algorithms\nks = [30, 100, 200, 65025]   ","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:59:15.856097Z","iopub.status.idle":"2022-09-29T10:59:15.857037Z","shell.execute_reply.started":"2022-09-29T10:59:15.856718Z","shell.execute_reply":"2022-09-29T10:59:15.856752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Flatten the dataset\n\nX_train = train_img.reshape((train_img.shape[0], 255*255))\ny_train = train_labels\nX_test = test_img.reshape((test_img.shape[0], 255*255))\ny_test = test_labels\nprint(X_train.shape)\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:59:15.858819Z","iopub.status.idle":"2022-09-29T10:59:15.859388Z","shell.execute_reply.started":"2022-09-29T10:59:15.859097Z","shell.execute_reply":"2022-09-29T10:59:15.859123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flat_test = S.transform(flat_test)\n# pca_test = pca.transform(flat_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:59:15.861803Z","iopub.status.idle":"2022-09-29T10:59:15.862683Z","shell.execute_reply.started":"2022-09-29T10:59:15.862355Z","shell.execute_reply":"2022-09-29T10:59:15.862383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Naive Bayes classifier","metadata":{}},{"cell_type":"code","source":"NBaccuracy = pd.DataFrame(index = ks, columns = algos)\nNB = GaussianNB()\n\nfor algo in algos:\n    \n    for n_feats in ks:\n        \n        feats = rankings[algo][:n_feats]\n        if algo == 'mi':\n            print(feats)\n        NB.fit(\n            X_train[:, feats], y_train,\n        ) \n        y_pred = NB.predict(X_test[:,feats])\n        cm1 = confusion_matrix(y_test, y_pred)\n        nb_accuracy = np.sum(np.diag(cm1))/np.sum(cm1)\n        NBaccuracy.loc[ks, algo] = nb_accuracy\n\n        print(f\"naive bayes accuracy {n_feats} features: \", nb_accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:59:15.864256Z","iopub.status.idle":"2022-09-29T10:59:15.865123Z","shell.execute_reply.started":"2022-09-29T10:59:15.864821Z","shell.execute_reply":"2022-09-29T10:59:15.864849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy Plot\nAccuracy of Naive Bayes model trained on different no of features and different feature selection algorithm.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure()\nax = plt.axes()\nx = ks\ny1 = NBaccuracy.pca.values.tolist() \ny2 = NBaccuracy.mrmr.values.tolist()\ny3 = NBaccuracy.f.values.tolist()\ny4 = NBaccuracy.mi.values.tolist() \n\nplt.plot(x, y1, '-g', linewidth=2)  \nplt.plot(x, y2, '-c', linewidth=2) \nplt.plot(x, y3, '-k', linewidth=2) \nplt.plot(x, y4, '-r', linewidth=2)\n\nplt.xlabel(\"No of Features\")\nplt.ylabel(\"Accuracy\");\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:59:15.866744Z","iopub.status.idle":"2022-09-29T10:59:15.867637Z","shell.execute_reply.started":"2022-09-29T10:59:15.867303Z","shell.execute_reply":"2022-09-29T10:59:15.867331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SVM (aka GOAT)","metadata":{}},{"cell_type":"code","source":"from sklearn import svm\n\nSVM = svm.SVC(kernel = \"rbf\", decision_function_shape = 'ovr')\n\nSVM.fit(pca_train, y_train)\n\ny_predict = SVM.predict(pca_test)\n\ncm2 = confusion_matrix(y_test, y_predict)\nacc2 = np.sum(np.diag(cm2))/np.sum(cm2)\nprint(\"SVM accuracy \\n\", acc2)\n\nSVMaccuracy = pd.DataFrame(index = ks, columns = algos)\nSVM = svm.SVC(kernel = \"rbf\", decision_function_shape = 'ovr')\n\nfor algo in algos:\n    \n    for nfeats in ks:\n        \n        feats = ranking[algo][:n_feats]\n\n        SVM.fit(\n            X_train[:, feats], y_train,\n        ) \n        y_pred = SVM.predict(X_test)\n        cm1 = confusion_matrix(y_test, y_pred)\n        svm_accuracy = np.sum(np.diag(cm1))/np.sum(cm1)\n        SVMaccuracy.loc[ks, algo] = svm_accuracy\n\n        print(f\"SVM accuracy {nfeats} features: \", svm_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:59:15.869280Z","iopub.status.idle":"2022-09-29T10:59:15.870203Z","shell.execute_reply.started":"2022-09-29T10:59:15.869845Z","shell.execute_reply":"2022-09-29T10:59:15.869913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy Plot for SVM\nAccuracy of support vector machine model trained on different no of features and different feature selection algorithm.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nmetrics = ['cityblock', 'cosine', 'minkowski']\nneighbors = range(3, 15)\nbest_acc = 0\nbest_ney = 0\nbest_acc = 0\nbest_cm = np.zeros((4, 4))\nbest_metric = ''\nfor metric in metrics :\n    for ney in neighbors:\n        knn = KNeighborsClassifier(n_neighbors = ney, metric = metric)\n        knn.fit(pca_train, y_train)\n        y_predict = knn.predict(pca_test)\n        cm = confusion_matrix(y_test, y_predict)\n        acc = np.sum(np.diag(cm))/np.sum(cm)\n        if acc>best_acc:\n            best_ney = ney\n            best_cm = cm\n            best_acc = acc\n            best_metric = metric\n\nprint(\"Best metric :\", best_metric)\nprint(\"Best k neighbors =\", best_ney)\nprint(\"Best acc =\", best_acc)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:59:15.871678Z","iopub.status.idle":"2022-09-29T10:59:15.872408Z","shell.execute_reply.started":"2022-09-29T10:59:15.872185Z","shell.execute_reply":"2022-09-29T10:59:15.872207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"n_comp = np.arange(3, 404, 50)\nacc = []\n\nfor n in n_comp:\n    pca = PCA(n_components =n)\n    pca_train = pca.fit_transform(flat_train)\n    \n    pca_test = pca.transform(flat_test)\n    \n    SVM = svm.SVC(kernel = \"rbf\", decision_function_shape = 'ovr')\n    SVM.fit(pca_train, y_train)\n    \n    y_predict = SVM.predict(pca_test)\n    \n    cm2 = confusion_matrix(y_test, y_predict)\n    acc2 = np.sum(np.diag(cm2))/np.sum(cm2)\n    \n    acc.append(acc2)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T13:25:26.125855Z","iopub.execute_input":"2022-09-27T13:25:26.126204Z","iopub.status.idle":"2022-09-27T13:27:08.813758Z","shell.execute_reply.started":"2022-09-27T13:25:26.126168Z","shell.execute_reply":"2022-09-27T13:27:08.812749Z"}}},{"cell_type":"markdown","source":"plt.figure()\nplt.grid()\nplt.plot(n_comp, acc)\nplt.xlabel(\"n_components\")\nplt.ylabel(\"SVM accuracy\")\nplt.title(\"SVM accuracy in function of number of PCA components kept\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T13:27:08.815078Z","iopub.execute_input":"2022-09-27T13:27:08.815455Z","iopub.status.idle":"2022-09-27T13:27:09.024322Z","shell.execute_reply.started":"2022-09-27T13:27:08.815418Z","shell.execute_reply":"2022-09-27T13:27:09.023327Z"}}},{"cell_type":"code","source":"# new_train = flat_train[:, selected_features]\n# new_test = flat_test[:, selected_features]\n\n# SVM = svm.SVC(kernel = \"rbf\", decision_function_shape = 'ovr')\n\n# SVM.fit(new_train, y_train)\n\n# y_predict = SVM.predict(new_test)\n\n# cm2 = confusion_matrix(y_test, y_predict)\n# acc2 = np.sum(np.diag(cm2))/np.sum(cm2)\n# print(\"SVM accuracy \\n\", acc2)","metadata":{"execution":{"iopub.status.busy":"2022-09-29T10:59:15.873933Z","iopub.status.idle":"2022-09-29T10:59:15.874424Z","shell.execute_reply.started":"2022-09-29T10:59:15.874136Z","shell.execute_reply":"2022-09-29T10:59:15.874224Z"},"trusted":true},"execution_count":null,"outputs":[]}]}