{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\n\n# Scikit-Learn â‰¥0.20 is required\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib as mlp\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-07T16:43:08.545412Z","iopub.execute_input":"2022-11-07T16:43:08.546690Z","iopub.status.idle":"2022-11-07T16:43:09.415825Z","shell.execute_reply.started":"2022-11-07T16:43:08.546551Z","shell.execute_reply":"2022-11-07T16:43:09.414716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"labels = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\ntrain_img = [] #contains the images used for training the model\ntest_img = []\ntrain_labels = [] #label of each image in x_train \ntest_labels = []\nTRAIN_PATH = '../input/brain-tumor-classification-mri/Training'\nTEST_PATH = '../input/brain-tumor-classification-mri/Testing'\nnew_size = (255, 255)\n\nfor label in labels:\n    img_dir = os.path.join(TRAIN_PATH, label)\n    for img_file in os.listdir(img_dir):\n        img = cv2.imread(f'{img_dir}/{img_file}')\n        img = cv2.resize(img, new_size)\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)/255\n        train_img.append(img)\n        train_labels.append(label)\n        \ntrain_img = np.stack(train_img)\ntrain_labels = np.stack(train_labels)\n\nprint(\"train_img shape : \", train_img.shape)\nprint(\"train_labels shape : \", train_labels.shape)\n\nfor label in labels:\n    img_dir = os.path.join(TEST_PATH, label)\n    for img_file in os.listdir(img_dir):\n        img = cv2.imread(f'{img_dir}/{img_file}')\n        img = cv2.resize(img, new_size)\n        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)/255\n        test_img.append(img)\n        test_labels.append(label)\n        \ntest_img = np.stack(test_img)\ntest_labels = np.stack(test_labels)\n\nprint(\"test_img shape : \", test_img.shape)\nprint(\"test_labels shape : \", test_labels.shape)\n\nclass_map = {\n    'no_tumor': 0,\n    'glioma_tumor': 1,\n    'pituitary_tumor': 2,\n    'meningioma_tumor': 3\n}\n\ntrain_labels = np.array([class_map[label] for label in train_labels])\ntest_labels = np.array([class_map[label] for label in test_labels])","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:43:09.418151Z","iopub.execute_input":"2022-11-07T16:43:09.418603Z","iopub.status.idle":"2022-11-07T16:43:43.487210Z","shell.execute_reply.started":"2022-11-07T16:43:09.418573Z","shell.execute_reply":"2022-11-07T16:43:43.485998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data pre-processing","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, MinMaxScaler #the Standard Scaler : X2 = (X1 - E(X1))/sqrt(Var(X1))\nfrom sklearn.decomposition import PCA\n\ntrain_img = train_img.reshape((train_img.shape[0], 255*255))\ntest_img = test_img.reshape((test_img.shape[0], 255*255))\nS = StandardScaler()\nX_train = S.fit_transform(train_img)\nX_test = S.transform(test_img)\nP = PCA(n_components = 100)\npca_train = P.fit_transform(X_train)\npca_test = P.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:43:43.489245Z","iopub.execute_input":"2022-11-07T16:43:43.490091Z","iopub.status.idle":"2022-11-07T16:44:10.303167Z","shell.execute_reply.started":"2022-11-07T16:43:43.490028Z","shell.execute_reply":"2022-11-07T16:44:10.301254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = np.hstack((pca_train, train_labels[:,None]))\ndata_test = np.hstack((pca_test, test_labels[:,None]))\n\nall_data = np.vstack((data_train, data_test))\nX = all_data[:,:-1]\ny = all_data[:,-1]","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:44:10.308996Z","iopub.execute_input":"2022-11-07T16:44:10.309689Z","iopub.status.idle":"2022-11-07T16:44:10.323313Z","shell.execute_reply.started":"2022-11-07T16:44:10.309615Z","shell.execute_reply":"2022-11-07T16:44:10.321759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Linear Classifier","metadata":{}},{"cell_type":"markdown","source":"This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning via the partial_fit method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.\n\nThis implementation works with data represented as dense or sparse arrays of floating point values for the features. The model it fits can be controlled with the loss parameter; by default, it fits a linear support vector machine (SVM).\n\nThe regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either the squared euclidean norm L2 or the absolute norm L1 or a combination of both (Elastic Net). If the parameter update crosses the 0.0 value because of the regularizer, the update is truncated to 0.0 to allow for learning sparse models and achieve online feature selection.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier \nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix, f1_score\nfrom sklearn.model_selection import cross_validate, cross_val_score","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:44:10.328606Z","iopub.execute_input":"2022-11-07T16:44:10.329787Z","iopub.status.idle":"2022-11-07T16:44:10.337066Z","shell.execute_reply.started":"2022-11-07T16:44:10.329728Z","shell.execute_reply":"2022-11-07T16:44:10.335577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = SGDClassifier(loss = 'squared_error')\nclf.fit(pca_train, train_labels)\nprint(\"Score on the training data set: \", clf.score(pca_train, train_labels))","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:44:10.339519Z","iopub.execute_input":"2022-11-07T16:44:10.340488Z","iopub.status.idle":"2022-11-07T16:44:11.287361Z","shell.execute_reply.started":"2022-11-07T16:44:10.340405Z","shell.execute_reply":"2022-11-07T16:44:11.283138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The score is extremelly poor, which means that our data is not linearly separable.","metadata":{}},{"cell_type":"code","source":"print(\"Score on the testing data set: \", clf.score(pca_test, test_labels))","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:44:11.294498Z","iopub.execute_input":"2022-11-07T16:44:11.296147Z","iopub.status.idle":"2022-11-07T16:44:11.306545Z","shell.execute_reply.started":"2022-11-07T16:44:11.296064Z","shell.execute_reply":"2022-11-07T16:44:11.305023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Indeed, on the testing data set, only 1 out of four sample are correctly classified. A random classification would give similar results.","metadata":{}},{"cell_type":"markdown","source":"# Logistic regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression ","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:44:11.308507Z","iopub.execute_input":"2022-11-07T16:44:11.310109Z","iopub.status.idle":"2022-11-07T16:44:11.317371Z","shell.execute_reply.started":"2022-11-07T16:44:11.310024Z","shell.execute_reply":"2022-11-07T16:44:11.315836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cls = LogisticRegression(penalty = 'none', max_iter = 1500, tol = 0.0001, multi_class = 'multinomial')\ncls.fit(pca_train, train_labels)\n\nprint(\"Score on the training data set: \", cls.score(pca_train, train_labels))\nprint(\"Score on the testing data set: \", cls.score(pca_test, test_labels))","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:44:11.319536Z","iopub.execute_input":"2022-11-07T16:44:11.321047Z","iopub.status.idle":"2022-11-07T16:44:15.151231Z","shell.execute_reply.started":"2022-11-07T16:44:11.320986Z","shell.execute_reply":"2022-11-07T16:44:15.149986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The score on the test set is poor, the logistic regression won't work effectively","metadata":{}},{"cell_type":"markdown","source":"### Testing the variation of the different learning parameters","metadata":{}},{"cell_type":"code","source":"ccp_alphas = np.linspace(0.0001, 0.01, 20)\nclfs = []\nfor alpha in ccp_alphas:\n    LC = SGDClassifier(loss = 'squared_error', alpha = alpha)\n    LC.fit(pca_train, train_labels)\n    clfs.append(LC)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:44:15.153233Z","iopub.execute_input":"2022-11-07T16:44:15.154033Z","iopub.status.idle":"2022-11-07T16:44:32.253748Z","shell.execute_reply.started":"2022-11-07T16:44:15.153991Z","shell.execute_reply":"2022-11-07T16:44:32.252549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_scores = [clf.score(pca_train, train_labels) for clf in clfs]\ntest_scores = [clf.score(pca_test, test_labels) for clf in clfs]\n\nfig, ax = plt.subplots(figsize=(10, 5))\nax.set_xlabel(\"alpha\")\nax.set_ylabel(\"accuracy\")\nax.set_title(\"Accuracy vs alpha for training and testing sets\")\nax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\nax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\nax.legend()\nax.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:44:32.255040Z","iopub.execute_input":"2022-11-07T16:44:32.255413Z","iopub.status.idle":"2022-11-07T16:44:32.608398Z","shell.execute_reply.started":"2022-11-07T16:44:32.255382Z","shell.execute_reply":"2022-11-07T16:44:32.607145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adaptive learning rate","metadata":{}},{"cell_type":"markdown","source":"As long as the training keeps decreasing, each time n_iter_no_change consecutive epochs fail to decrease the training loss by tol or fail to increase validation score by tol if early_stopping is True, the current learning rate is divided by 5.","metadata":{}},{"cell_type":"code","source":"clf = SGDClassifier(loss = 'squared_error', learning_rate = 'adaptive', eta0 = 0.001, max_iter = 15000)\nclf.fit(pca_train, train_labels)\nclf.score(pca_train, train_labels)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:44:32.609983Z","iopub.execute_input":"2022-11-07T16:44:32.610942Z","iopub.status.idle":"2022-11-07T16:44:43.998451Z","shell.execute_reply.started":"2022-11-07T16:44:32.610896Z","shell.execute_reply":"2022-11-07T16:44:43.996861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Different type of loss","metadata":{}},{"cell_type":"code","source":"loss_func = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']\n\nclfs = []\nfor func in loss_func:\n    clf = SGDClassifier(loss = func)\n    clf.fit(pca_train, train_labels)\n    clfs.append(clf)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:44:44.001332Z","iopub.execute_input":"2022-11-07T16:44:44.002518Z","iopub.status.idle":"2022-11-07T16:44:52.897285Z","shell.execute_reply.started":"2022-11-07T16:44:44.002452Z","shell.execute_reply":"2022-11-07T16:44:52.896112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_scores = [clf.score(pca_train, train_labels) for clf in clfs]\ntest_scores = [clf.score(pca_test, test_labels) for clf in clfs]\n\nnumber = [i+1 for i in range(len(loss_func))]\n\nfig, ax = plt.subplots(figsize=(25, 5))\nax.set_xlabel(\"Loss function\")\nax.set_ylabel(\"Accuracy\")\nax.set_title(\"Accuracy vs loss function for training sets\")\nax.bar(number, train_scores, tick_label = loss_func, width = 0.8, color = ['blue']) \nax.legend()\nax.grid()\nplt.show()\n\nfig, ax = plt.subplots(figsize=(25, 5))\nax.set_xlabel(\"Loss function\")\nax.set_ylabel(\"Accuracy\")\nax.set_title(\"Accuracy vs loss function for testing sets\")\nax.bar(number, test_scores, tick_label = loss_func, width = 0.8, color = ['red'])\nax.legend()\nax.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:50:35.395698Z","iopub.execute_input":"2022-11-07T16:50:35.396892Z","iopub.status.idle":"2022-11-07T16:50:35.997402Z","shell.execute_reply.started":"2022-11-07T16:50:35.396841Z","shell.execute_reply":"2022-11-07T16:50:35.995876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### From what we can see here, the 'hinge' solver performs better. However the accuracy on the testing set is still poor. Let's try ot improve that result.","metadata":{}},{"cell_type":"code","source":"ccp_alphas = np.linspace(0.0001, 0.01, 500)\nclfs = []\nfor alpha in ccp_alphas:\n    LC = SGDClassifier(loss = 'hinge', alpha = alpha)\n    LC.fit(pca_train, train_labels)\n    clfs.append(LC)","metadata":{"execution":{"iopub.status.busy":"2022-11-07T16:59:15.846198Z","iopub.execute_input":"2022-11-07T16:59:15.847294Z","iopub.status.idle":"2022-11-07T17:00:53.258396Z","shell.execute_reply.started":"2022-11-07T16:59:15.847246Z","shell.execute_reply":"2022-11-07T17:00:53.257294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_scores = [clf.score(pca_train, train_labels) for clf in clfs]\ntest_scores = [clf.score(pca_test, test_labels) for clf in clfs]\n\nfig, ax = plt.subplots(figsize=(30, 5))\nax.set_xlabel(\"alpha\")\nax.set_ylabel(\"accuracy\")\nax.set_title(\"Accuracy vs alpha for training and testing sets\")\nax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\nax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\nax.legend()\nax.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-07T17:00:53.260369Z","iopub.execute_input":"2022-11-07T17:00:53.260699Z","iopub.status.idle":"2022-11-07T17:00:54.678944Z","shell.execute_reply.started":"2022-11-07T17:00:53.260672Z","shell.execute_reply":"2022-11-07T17:00:54.677792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\npenaltys = ['l1', 'l2', 'elasticnet']\n\nP = []\n\nfor pen in penaltys:\n    print('\\nPenalty mode: ', pen)\n    p1, p2 = [], []\n    for i in tqdm (range (50), desc=\"Loading...\"):\n        clf = SGDClassifier(loss = 'hinge', penalty = pen)\n        clf.fit(pca_train, train_labels)\n        p1.append(clf.score(pca_train, train_labels))\n        p2.append(clf.score(pca_test, test_labels))\n    \n    P.append([p1, p2])","metadata":{"execution":{"iopub.status.busy":"2022-11-07T18:57:27.383022Z","iopub.execute_input":"2022-11-07T18:57:27.383838Z","iopub.status.idle":"2022-11-07T18:58:46.590236Z","shell.execute_reply.started":"2022-11-07T18:57:27.383793Z","shell.execute_reply":"2022-11-07T18:58:46.589017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_train = []\nscores_test = []\n\nfor set in P:\n    sum_train = 0\n    for i in set[0]:\n        sum_train += i\n    scores_train.append(sum_train/len(set[0]))\n    \n    sum_test = 0\n    for i in set[1]:\n        sum_test += i\n    scores_test.append(sum_test/len(set[1]))\n    \nfig, (ax1, ax2) = plt.subplots(2, figsize = (10, 10))\n\nax1.set_xlabel(\"Penalty mode\")\nax1.set_ylabel(\"Mean accuracy\")\nax1.set_title(\"Accuracy vs penalty mode for training sets over 50 classifiers\")\nax1.bar([1, 2, 3], scores_train, tick_label = penaltys, width = 0.8, color = ['blue'])\nax1.set_ylim(0.7, 0.8)\nax1.legend()\nax1.grid()\n\nax2.set_xlabel(\"alpha\")\nax2.set_ylabel(\"Mean accuracy\")\nax2.set_title(\"Mean accuracy vs penalty mode for testing sets over 50 classifiers\")\nax2.bar([1, 2, 3], scores_test, tick_label = penaltys, width = 0.8, color = ['red'])\nax2.set_ylim(0.4, 0.50)\nax2.legend()\nax2.grid()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-07T18:58:46.592534Z","iopub.execute_input":"2022-11-07T18:58:46.593342Z","iopub.status.idle":"2022-11-07T18:58:46.967439Z","shell.execute_reply.started":"2022-11-07T18:58:46.593297Z","shell.execute_reply":"2022-11-07T18:58:46.966342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}